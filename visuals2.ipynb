{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "values = []\n",
    "colors = ['r', 'g', 'y', 'k', 'b']\n",
    "histories = np.load('models/vgg16_kfolds.npy', allow_pickle=True)\n",
    "for i in range(1, 6):\n",
    "    jc = histories[i-1]\n",
    "    epoches = jc['epoch']\n",
    "    epoches = epoches + [len(epoches)]\n",
    "    train_acc = [0] + jc['history']['accuracy']\n",
    "    val_acc = [0] + jc['history']['val_accuracy']\n",
    "\n",
    "    plt.plot(epoches, train_acc, '--', color=colors[i-1])\n",
    "    plt.plot(epoches, val_acc, color=colors[i-1])\n",
    "    plt.xlabel('epochs', fontsize=15)\n",
    "    plt.ylabel('accuracy', fontsize=15)\n",
    "    values.append('fold{}'.format(i))\n",
    "# plt.legend(['train', 'val'], fontsize=12)\n",
    "plt.title('TL VGG16 5 Fold CV', fontsize=15)\n",
    "# plt.ylim([0.90, .95])\n",
    "plt.savefig('figures/tl_vgg16_5foldCV.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from modules import utils, vgg16, fcnn, cifar_vgg\n",
    "    \n",
    "model = vgg16(train=False)\n",
    "model = fcnn(train=False, model_path='models/allFeatures_pca1000.h5', \n",
    "             features_path='data/allFeatures_pca1000_features.npy')\n",
    "model = cifar_vgg(train=False)\n",
    "utils.plot_confusion_matrix(model, title='CIFAR-VGG16', save_path='figures/cifar_vgg_cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample three correct and wrong classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model of interest and predict on testing dataset\n",
    "from modules import fcnn\n",
    "\n",
    "model = fcnn(train=False, model_path='models/allFeatures_pca1000.h5', \n",
    "             features_path='data/allFeatures_pca1000_features.npy')\n",
    "preds = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sample three classes that were correct and three that were not\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "random.seed(334)\n",
    "\n",
    "pred_y = []\n",
    "for i in range(preds.shape[0]):\n",
    "    pred_y.append(np.argmax(preds[i]))\n",
    "    \n",
    "true_y = [int(i) for i in list(model.y_test)]\n",
    "\n",
    "correct_i = []\n",
    "incorrect_i = []\n",
    "\n",
    "for i in range(len(pred_y)):\n",
    "    if pred_y[i] == true_y[i]:\n",
    "        correct_i.append(i)\n",
    "    else:\n",
    "        incorrect_i.append(i)\n",
    "\n",
    "# shuffle the lists\n",
    "random.shuffle(correct_i)\n",
    "random.shuffle(incorrect_i)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "LABELS = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "\n",
    "# for the first three show the image and on the bottom label put the percentages\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(10, 8))\n",
    "for j, i in enumerate(correct_i[:3]):\n",
    "    ax[j].imshow(x_test[i], interpolation='bicubic')\n",
    "    ax[j].axes.get_yaxis().set_visible(False)\n",
    "    ax[j].tick_params(axis=u'both', which=u'both',length=0)\n",
    "    ax[j].set_xticklabels([])\n",
    "    probs = [float(p) for p in preds[i]]\n",
    "    labels = LABELS.copy()\n",
    "    \n",
    "    # sort the two lists\n",
    "    probs, labels = (list(t) for t in zip(*sorted(zip(probs, labels))))\n",
    "    ax[j].set_xlabel('%s: %.2f  | %s: %.2E |  %s: %.2E' % (\n",
    "        labels[-1], probs[-1], labels[-2], probs[-2], labels[-3], probs[-3]\n",
    "    ))\n",
    "plt.savefig('figures/correct_samples.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, figsize=(10, 8))\n",
    "for j, i in enumerate(incorrect_i[:3]):\n",
    "    ax[j].imshow(x_test[i], interpolation='bicubic')\n",
    "    ax[j].axes.get_yaxis().set_visible(False)\n",
    "    ax[j].tick_params(axis=u'both', which=u'both',length=0)\n",
    "    ax[j].set_xticklabels([])\n",
    "    probs = [float(p) for p in preds[i]]\n",
    "    labels = LABELS.copy()\n",
    "    \n",
    "    # sort the two lists\n",
    "    probs, labels = (list(t) for t in zip(*sorted(zip(probs, labels))))\n",
    "    ax[j].set_xlabel('%s: %.3f  | %s: %.3f |  %s: %.2E' % (\n",
    "        labels[-1], probs[-1], labels[-2], probs[-2], labels[-3], probs[-3]\n",
    "    ))\n",
    "plt.savefig('figures/incorrect_samples.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kfold cross validation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2781 - accuracy: 0.6516\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75100, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 54s 87ms/step - loss: 1.2780 - accuracy: 0.6517 - val_loss: 0.9736 - val_accuracy: 0.7510\n",
      "Epoch 2/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.8607 - accuracy: 0.7920\n",
      "Epoch 00002: val_accuracy improved from 0.75100 to 0.77444, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.8609 - accuracy: 0.7921 - val_loss: 0.9120 - val_accuracy: 0.7744\n",
      "Epoch 3/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7416 - accuracy: 0.8294\n",
      "Epoch 00003: val_accuracy improved from 0.77444 to 0.81971, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.7416 - accuracy: 0.8295 - val_loss: 0.7616 - val_accuracy: 0.8197\n",
      "Epoch 4/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6528 - accuracy: 0.8590\n",
      "Epoch 00004: val_accuracy improved from 0.81971 to 0.82232, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.6525 - accuracy: 0.8591 - val_loss: 0.7567 - val_accuracy: 0.8223\n",
      "Epoch 5/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5877 - accuracy: 0.8829\n",
      "Epoch 00005: val_accuracy improved from 0.82232 to 0.82873, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.5877 - accuracy: 0.8829 - val_loss: 0.7487 - val_accuracy: 0.8287\n",
      "Epoch 6/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5329 - accuracy: 0.8993\n",
      "Epoch 00006: val_accuracy improved from 0.82873 to 0.84115, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.5328 - accuracy: 0.8993 - val_loss: 0.7142 - val_accuracy: 0.8411\n",
      "Epoch 7/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.9129\n",
      "Epoch 00007: val_accuracy did not improve from 0.84115\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.4893 - accuracy: 0.9129 - val_loss: 0.7384 - val_accuracy: 0.8349\n",
      "Epoch 8/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4466 - accuracy: 0.9265\n",
      "Epoch 00008: val_accuracy improved from 0.84115 to 0.85837, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.4465 - accuracy: 0.9265 - val_loss: 0.6723 - val_accuracy: 0.8584\n",
      "Epoch 9/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4020 - accuracy: 0.9424\n",
      "Epoch 00009: val_accuracy did not improve from 0.85837\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4020 - accuracy: 0.9424 - val_loss: 0.7114 - val_accuracy: 0.8538\n",
      "Epoch 10/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3731 - accuracy: 0.9505\n",
      "Epoch 00010: val_accuracy did not improve from 0.85837\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3733 - accuracy: 0.9505 - val_loss: 0.7459 - val_accuracy: 0.8518\n",
      "Epoch 11/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3425 - accuracy: 0.9609\n",
      "Epoch 00011: val_accuracy improved from 0.85837 to 0.86118, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.3424 - accuracy: 0.9609 - val_loss: 0.7002 - val_accuracy: 0.8612\n",
      "Epoch 12/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3135 - accuracy: 0.9697\n",
      "Epoch 00012: val_accuracy improved from 0.86118 to 0.86518, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3135 - accuracy: 0.9697 - val_loss: 0.6965 - val_accuracy: 0.8652\n",
      "Epoch 13/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9755\n",
      "Epoch 00013: val_accuracy did not improve from 0.86518\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2943 - accuracy: 0.9754 - val_loss: 0.7793 - val_accuracy: 0.8544\n",
      "Epoch 14/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9792\n",
      "Epoch 00014: val_accuracy did not improve from 0.86518\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2819 - accuracy: 0.9792 - val_loss: 0.7260 - val_accuracy: 0.8640\n",
      "Epoch 15/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2612 - accuracy: 0.9850\n",
      "Epoch 00015: val_accuracy improved from 0.86518 to 0.86739, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.2613 - accuracy: 0.9849 - val_loss: 0.7309 - val_accuracy: 0.8674\n",
      "Epoch 16/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.9888\n",
      "Epoch 00016: val_accuracy improved from 0.86739 to 0.87260, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2497 - accuracy: 0.9887 - val_loss: 0.7117 - val_accuracy: 0.8726\n",
      "Epoch 17/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2407 - accuracy: 0.9907\n",
      "Epoch 00017: val_accuracy did not improve from 0.87260\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2407 - accuracy: 0.9907 - val_loss: 0.7601 - val_accuracy: 0.8642\n",
      "Epoch 18/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2351 - accuracy: 0.9914\n",
      "Epoch 00018: val_accuracy did not improve from 0.87260\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2351 - accuracy: 0.9915 - val_loss: 0.8076 - val_accuracy: 0.8618\n",
      "Epoch 19/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9924\n",
      "Epoch 00019: val_accuracy improved from 0.87260 to 0.87320, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2298 - accuracy: 0.9924 - val_loss: 0.7283 - val_accuracy: 0.8732\n",
      "Epoch 20/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2229 - accuracy: 0.9933\n",
      "Epoch 00020: val_accuracy did not improve from 0.87320\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2229 - accuracy: 0.9933 - val_loss: 0.8268 - val_accuracy: 0.8616\n",
      "Epoch 21/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9941\n",
      "Epoch 00021: val_accuracy improved from 0.87320 to 0.87740, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2190 - accuracy: 0.9941 - val_loss: 0.7369 - val_accuracy: 0.8774\n",
      "Epoch 22/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9981\n",
      "Epoch 00022: val_accuracy improved from 0.87740 to 0.88361, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2052 - accuracy: 0.9981 - val_loss: 0.7213 - val_accuracy: 0.8836\n",
      "Epoch 23/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.9973\n",
      "Epoch 00023: val_accuracy did not improve from 0.88361\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2048 - accuracy: 0.9973 - val_loss: 0.7599 - val_accuracy: 0.8786\n",
      "Epoch 24/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9986\n",
      "Epoch 00024: val_accuracy did not improve from 0.88361\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1981 - accuracy: 0.9985 - val_loss: 0.7785 - val_accuracy: 0.8770\n",
      "Epoch 25/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9973\n",
      "Epoch 00025: val_accuracy did not improve from 0.88361\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1995 - accuracy: 0.9973 - val_loss: 0.7471 - val_accuracy: 0.8812\n",
      "Epoch 26/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9993\n",
      "Epoch 00026: val_accuracy did not improve from 0.88361\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1914 - accuracy: 0.9993 - val_loss: 0.7864 - val_accuracy: 0.8800\n",
      "Epoch 27/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.9998\n",
      "Epoch 00027: val_accuracy improved from 0.88361 to 0.88722, saving model to models/vgg16_fold1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1868 - accuracy: 0.9998 - val_loss: 0.7209 - val_accuracy: 0.8872\n",
      "Epoch 28/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9999\n",
      "Epoch 00028: val_accuracy did not improve from 0.88722\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1837 - accuracy: 0.9999 - val_loss: 0.7101 - val_accuracy: 0.8864\n",
      "Epoch 29/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9999\n",
      "Epoch 00029: val_accuracy improved from 0.88722 to 0.89002, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1813 - accuracy: 0.9999 - val_loss: 0.7097 - val_accuracy: 0.8900\n",
      "Epoch 30/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.89002\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1789 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8896\n",
      "Epoch 31/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy improved from 0.89002 to 0.89042, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1764 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.8904\n",
      "Epoch 32/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8900\n",
      "Epoch 33/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1720 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 0.7043 - val_accuracy: 0.8898\n",
      "Epoch 34/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1698 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy improved from 0.89042 to 0.89143, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1698 - accuracy: 1.0000 - val_loss: 0.7022 - val_accuracy: 0.8914\n",
      "Epoch 35/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 0.6991 - val_accuracy: 0.8900\n",
      "Epoch 36/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1655 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 0.7038 - val_accuracy: 0.8890\n",
      "Epoch 37/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1635 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1635 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8902\n",
      "Epoch 38/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1614 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.8898\n",
      "Epoch 39/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1594 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1594 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8900\n",
      "Epoch 40/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1574 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8894\n",
      "Epoch 41/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1555 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1555 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8900\n",
      "Epoch 42/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1535 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.89143\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1535 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8912\n",
      "Epoch 43/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1516 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy improved from 0.89143 to 0.89203, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1516 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8920\n",
      "Epoch 44/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1497 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8910\n",
      "Epoch 45/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8908\n",
      "Epoch 46/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1460 - accuracy: 1.0000 - val_loss: 0.6867 - val_accuracy: 0.8918\n",
      "Epoch 47/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1442 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.6871 - val_accuracy: 0.8912\n",
      "Epoch 48/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8910\n",
      "Epoch 49/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1407 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8914\n",
      "Epoch 50/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.8914\n",
      "Epoch 51/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 0.8914\n",
      "Epoch 52/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.89203\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8918\n",
      "Epoch 53/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 1.0000\n",
      "Epoch 00053: val_accuracy improved from 0.89203 to 0.89363, saving model to models/vgg16_fold1.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1338 - accuracy: 1.0000 - val_loss: 0.6775 - val_accuracy: 0.8936\n",
      "Epoch 54/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 1.0000\n",
      "Epoch 00054: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8920\n",
      "Epoch 55/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 1.0000\n",
      "Epoch 00055: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.8922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 1.0000\n",
      "Epoch 00056: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1289 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 0.8916\n",
      "Epoch 57/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1273 - accuracy: 1.0000 - val_loss: 0.6734 - val_accuracy: 0.8916\n",
      "Epoch 58/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1257 - accuracy: 1.0000\n",
      "Epoch 00058: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1257 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8920\n",
      "Epoch 59/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 1.0000\n",
      "Epoch 00059: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 0.6714 - val_accuracy: 0.8930\n",
      "Epoch 60/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 1.0000\n",
      "Epoch 00060: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.8916\n",
      "Epoch 61/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 1.0000\n",
      "Epoch 00061: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1210 - accuracy: 1.0000 - val_loss: 0.6679 - val_accuracy: 0.8916\n",
      "Epoch 62/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 0.8922\n",
      "Epoch 63/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 1.0000\n",
      "Epoch 00063: val_accuracy did not improve from 0.89363\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1181 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.8916\n",
      "Epoch 00063: early stopping\n",
      "Epoch 1/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2342 - accuracy: 0.6652\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71895, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 1.2339 - accuracy: 0.6653 - val_loss: 1.0421 - val_accuracy: 0.7190\n",
      "Epoch 2/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.8364 - accuracy: 0.8000\n",
      "Epoch 00002: val_accuracy improved from 0.71895 to 0.79768, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.8362 - accuracy: 0.8001 - val_loss: 0.8522 - val_accuracy: 0.7977\n",
      "Epoch 3/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7169 - accuracy: 0.8397\n",
      "Epoch 00003: val_accuracy did not improve from 0.79768\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.7168 - accuracy: 0.8397 - val_loss: 0.8652 - val_accuracy: 0.7957\n",
      "Epoch 4/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6350 - accuracy: 0.8649\n",
      "Epoch 00004: val_accuracy improved from 0.79768 to 0.83814, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.6352 - accuracy: 0.8648 - val_loss: 0.7189 - val_accuracy: 0.8381\n",
      "Epoch 5/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5705 - accuracy: 0.8877\n",
      "Epoch 00005: val_accuracy improved from 0.83814 to 0.84135, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.5704 - accuracy: 0.8878 - val_loss: 0.7094 - val_accuracy: 0.8413\n",
      "Epoch 6/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5162 - accuracy: 0.9048\n",
      "Epoch 00006: val_accuracy improved from 0.84135 to 0.84856, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.5161 - accuracy: 0.9048 - val_loss: 0.6978 - val_accuracy: 0.8486\n",
      "Epoch 7/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.9198\n",
      "Epoch 00007: val_accuracy improved from 0.84856 to 0.85717, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4730 - accuracy: 0.9198 - val_loss: 0.6753 - val_accuracy: 0.8572\n",
      "Epoch 8/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4306 - accuracy: 0.9330\n",
      "Epoch 00008: val_accuracy improved from 0.85717 to 0.86579, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4305 - accuracy: 0.9330 - val_loss: 0.6650 - val_accuracy: 0.8658\n",
      "Epoch 9/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.9488\n",
      "Epoch 00009: val_accuracy did not improve from 0.86579\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3836 - accuracy: 0.9488 - val_loss: 0.7173 - val_accuracy: 0.8524\n",
      "Epoch 10/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3617 - accuracy: 0.9547\n",
      "Epoch 00010: val_accuracy improved from 0.86579 to 0.86779, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3616 - accuracy: 0.9547 - val_loss: 0.6861 - val_accuracy: 0.8678\n",
      "Epoch 11/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.9658\n",
      "Epoch 00011: val_accuracy did not improve from 0.86779\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3280 - accuracy: 0.9658 - val_loss: 0.6831 - val_accuracy: 0.8632\n",
      "Epoch 12/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3036 - accuracy: 0.9732\n",
      "Epoch 00012: val_accuracy improved from 0.86779 to 0.86999, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.3036 - accuracy: 0.9732 - val_loss: 0.6928 - val_accuracy: 0.8700\n",
      "Epoch 13/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9803\n",
      "Epoch 00013: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2833 - accuracy: 0.9803 - val_loss: 0.7434 - val_accuracy: 0.8570\n",
      "Epoch 14/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2769 - accuracy: 0.9806\n",
      "Epoch 00014: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.2769 - accuracy: 0.9807 - val_loss: 0.7635 - val_accuracy: 0.8636\n",
      "Epoch 15/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9847\n",
      "Epoch 00015: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2624 - accuracy: 0.9847 - val_loss: 0.7690 - val_accuracy: 0.8598\n",
      "Epoch 16/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9896\n",
      "Epoch 00016: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.2480 - accuracy: 0.9895 - val_loss: 0.7484 - val_accuracy: 0.8674\n",
      "Epoch 17/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2402 - accuracy: 0.9909\n",
      "Epoch 00017: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2402 - accuracy: 0.9909 - val_loss: 0.7896 - val_accuracy: 0.8632\n",
      "Epoch 18/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9946\n",
      "Epoch 00018: val_accuracy improved from 0.86999 to 0.88201, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2275 - accuracy: 0.9946 - val_loss: 0.7102 - val_accuracy: 0.8820\n",
      "Epoch 19/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2214 - accuracy: 0.9955\n",
      "Epoch 00019: val_accuracy did not improve from 0.88201\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2214 - accuracy: 0.9955 - val_loss: 0.7328 - val_accuracy: 0.8772\n",
      "Epoch 20/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9950\n",
      "Epoch 00020: val_accuracy did not improve from 0.88201\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2196 - accuracy: 0.9950 - val_loss: 0.8012 - val_accuracy: 0.8668\n",
      "Epoch 21/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9968\n",
      "Epoch 00021: val_accuracy did not improve from 0.88201\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2127 - accuracy: 0.9968 - val_loss: 0.8885 - val_accuracy: 0.8554\n",
      "Epoch 22/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2098 - accuracy: 0.9967\n",
      "Epoch 00022: val_accuracy did not improve from 0.88201\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.2097 - accuracy: 0.9967 - val_loss: 0.7488 - val_accuracy: 0.8758\n",
      "Epoch 23/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.9981\n",
      "Epoch 00023: val_accuracy did not improve from 0.88201\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2026 - accuracy: 0.9981 - val_loss: 0.7195 - val_accuracy: 0.8816\n",
      "Epoch 24/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9996\n",
      "Epoch 00024: val_accuracy improved from 0.88201 to 0.88442, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1964 - accuracy: 0.9996 - val_loss: 0.7063 - val_accuracy: 0.8844\n",
      "Epoch 25/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9998\n",
      "Epoch 00025: val_accuracy improved from 0.88442 to 0.88962, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1923 - accuracy: 0.9998 - val_loss: 0.6936 - val_accuracy: 0.8896\n",
      "Epoch 26/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 1.0000\n",
      "Epoch 00026: val_accuracy did not improve from 0.88962\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1888 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8882\n",
      "Epoch 27/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1863 - accuracy: 1.0000\n",
      "Epoch 00027: val_accuracy did not improve from 0.88962\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 0.6945 - val_accuracy: 0.8890\n",
      "Epoch 28/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 1.0000\n",
      "Epoch 00028: val_accuracy improved from 0.88962 to 0.89163, saving model to models/vgg16_fold2.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1839 - accuracy: 1.0000 - val_loss: 0.6866 - val_accuracy: 0.8916\n",
      "Epoch 29/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1815 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8874\n",
      "Epoch 30/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 50s 80ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.8902\n",
      "Epoch 31/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1768 - accuracy: 1.0000 - val_loss: 0.6861 - val_accuracy: 0.8892\n",
      "Epoch 32/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1747 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 0.8880\n",
      "Epoch 33/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1724 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1724 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8892\n",
      "Epoch 34/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1703 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 0.8894\n",
      "Epoch 35/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1681 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8894\n",
      "Epoch 36/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1660 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 0.8908\n",
      "Epoch 37/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1639 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8902\n",
      "Epoch 38/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.89163\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.6774 - val_accuracy: 0.8912\n",
      "Epoch 00038: early stopping\n",
      "Epoch 1/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2380 - accuracy: 0.6639\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70613, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 1.2379 - accuracy: 0.6641 - val_loss: 1.1289 - val_accuracy: 0.7061\n",
      "Epoch 2/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.8462 - accuracy: 0.7949\n",
      "Epoch 00002: val_accuracy improved from 0.70613 to 0.80389, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.8459 - accuracy: 0.7950 - val_loss: 0.8396 - val_accuracy: 0.8039\n",
      "Epoch 3/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7226 - accuracy: 0.8363\n",
      "Epoch 00003: val_accuracy improved from 0.80389 to 0.82873, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.7226 - accuracy: 0.8363 - val_loss: 0.7555 - val_accuracy: 0.8287\n",
      "Epoch 4/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6353 - accuracy: 0.8660\n",
      "Epoch 00004: val_accuracy did not improve from 0.82873\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.6353 - accuracy: 0.8660 - val_loss: 0.7748 - val_accuracy: 0.8285\n",
      "Epoch 5/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5763 - accuracy: 0.8852\n",
      "Epoch 00005: val_accuracy improved from 0.82873 to 0.83454, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.5761 - accuracy: 0.8852 - val_loss: 0.7525 - val_accuracy: 0.8345\n",
      "Epoch 6/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.9022\n",
      "Epoch 00006: val_accuracy improved from 0.83454 to 0.85397, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.5234 - accuracy: 0.9023 - val_loss: 0.6812 - val_accuracy: 0.8540\n",
      "Epoch 7/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.9185\n",
      "Epoch 00007: val_accuracy improved from 0.85397 to 0.85477, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.4759 - accuracy: 0.9186 - val_loss: 0.7036 - val_accuracy: 0.8548\n",
      "Epoch 8/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4282 - accuracy: 0.9328\n",
      "Epoch 00008: val_accuracy improved from 0.85477 to 0.86338, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4281 - accuracy: 0.9328 - val_loss: 0.6882 - val_accuracy: 0.8634\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 0.3960 - accuracy: 0.9431\n",
      "Epoch 00009: val_accuracy did not improve from 0.86338\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.3961 - accuracy: 0.9431 - val_loss: 0.7395 - val_accuracy: 0.8401\n",
      "Epoch 10/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3581 - accuracy: 0.9581\n",
      "Epoch 00010: val_accuracy did not improve from 0.86338\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3583 - accuracy: 0.9580 - val_loss: 0.7068 - val_accuracy: 0.8572\n",
      "Epoch 11/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3340 - accuracy: 0.9631\n",
      "Epoch 00011: val_accuracy improved from 0.86338 to 0.87139, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3340 - accuracy: 0.9631 - val_loss: 0.6780 - val_accuracy: 0.8714\n",
      "Epoch 12/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.9723\n",
      "Epoch 00012: val_accuracy did not improve from 0.87139\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.3090 - accuracy: 0.9723 - val_loss: 0.7086 - val_accuracy: 0.8638\n",
      "Epoch 13/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2926 - accuracy: 0.9762\n",
      "Epoch 00013: val_accuracy improved from 0.87139 to 0.87200, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2927 - accuracy: 0.9761 - val_loss: 0.7174 - val_accuracy: 0.8720\n",
      "Epoch 14/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.9806\n",
      "Epoch 00014: val_accuracy did not improve from 0.87200\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2770 - accuracy: 0.9806 - val_loss: 0.7663 - val_accuracy: 0.8590\n",
      "Epoch 15/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9845\n",
      "Epoch 00015: val_accuracy did not improve from 0.87200\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2639 - accuracy: 0.9844 - val_loss: 0.7906 - val_accuracy: 0.8554\n",
      "Epoch 16/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2480 - accuracy: 0.9894\n",
      "Epoch 00016: val_accuracy did not improve from 0.87200\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.2479 - accuracy: 0.9894 - val_loss: 0.7546 - val_accuracy: 0.8686\n",
      "Epoch 17/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.9904\n",
      "Epoch 00017: val_accuracy did not improve from 0.87200\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2406 - accuracy: 0.9904 - val_loss: 0.7424 - val_accuracy: 0.8684\n",
      "Epoch 18/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2315 - accuracy: 0.9929\n",
      "Epoch 00018: val_accuracy did not improve from 0.87200\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2314 - accuracy: 0.9929 - val_loss: 0.7924 - val_accuracy: 0.8658\n",
      "Epoch 19/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9955\n",
      "Epoch 00019: val_accuracy improved from 0.87200 to 0.87400, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2212 - accuracy: 0.9955 - val_loss: 0.7517 - val_accuracy: 0.8740\n",
      "Epoch 20/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9943\n",
      "Epoch 00020: val_accuracy did not improve from 0.87400\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2213 - accuracy: 0.9943 - val_loss: 0.8007 - val_accuracy: 0.8662\n",
      "Epoch 21/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9940\n",
      "Epoch 00021: val_accuracy improved from 0.87400 to 0.87800, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2190 - accuracy: 0.9940 - val_loss: 0.7508 - val_accuracy: 0.8780\n",
      "Epoch 22/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2075 - accuracy: 0.9972\n",
      "Epoch 00022: val_accuracy did not improve from 0.87800\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2075 - accuracy: 0.9972 - val_loss: 0.7589 - val_accuracy: 0.8754\n",
      "Epoch 23/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9973\n",
      "Epoch 00023: val_accuracy did not improve from 0.87800\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.2042 - accuracy: 0.9973 - val_loss: 0.8399 - val_accuracy: 0.8618\n",
      "Epoch 24/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9970\n",
      "Epoch 00024: val_accuracy improved from 0.87800 to 0.87921, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2024 - accuracy: 0.9970 - val_loss: 0.7589 - val_accuracy: 0.8792\n",
      "Epoch 25/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1945 - accuracy: 0.9989\n",
      "Epoch 00025: val_accuracy improved from 0.87921 to 0.88782, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1945 - accuracy: 0.9989 - val_loss: 0.7156 - val_accuracy: 0.8878\n",
      "Epoch 26/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.9993\n",
      "Epoch 00026: val_accuracy did not improve from 0.88782\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1905 - accuracy: 0.9993 - val_loss: 0.7454 - val_accuracy: 0.8826\n",
      "Epoch 27/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.9996\n",
      "Epoch 00027: val_accuracy improved from 0.88782 to 0.88942, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1872 - accuracy: 0.9996 - val_loss: 0.7324 - val_accuracy: 0.8894\n",
      "Epoch 28/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.9996\n",
      "Epoch 00028: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1850 - accuracy: 0.9996 - val_loss: 0.7131 - val_accuracy: 0.8848\n",
      "Epoch 29/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9999\n",
      "Epoch 00029: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1814 - accuracy: 0.9999 - val_loss: 0.7134 - val_accuracy: 0.8880\n",
      "Epoch 30/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1785 - accuracy: 1.0000 - val_loss: 0.7073 - val_accuracy: 0.8874\n",
      "Epoch 31/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy improved from 0.88942 to 0.88962, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1762 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8896\n",
      "Epoch 32/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy improved from 0.88962 to 0.89022, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.8902\n",
      "Epoch 33/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy improved from 0.89022 to 0.89123, saving model to models/vgg16_fold3.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.7045 - val_accuracy: 0.8912\n",
      "Epoch 34/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1695 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8896\n",
      "Epoch 35/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1674 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1674 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.8904\n",
      "Epoch 36/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1654 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8904\n",
      "Epoch 37/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.7034 - val_accuracy: 0.8906\n",
      "Epoch 38/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1612 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.8908\n",
      "Epoch 39/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1592 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.8902\n",
      "Epoch 40/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8904\n",
      "Epoch 41/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.6985 - val_accuracy: 0.8904\n",
      "Epoch 42/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1533 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8908\n",
      "Epoch 43/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.6972 - val_accuracy: 0.8910\n",
      "Epoch 00043: early stopping\n",
      "Epoch 1/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2386 - accuracy: 0.6647\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75881, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 1.2384 - accuracy: 0.6649 - val_loss: 0.9411 - val_accuracy: 0.7588\n",
      "Epoch 2/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.8424 - accuracy: 0.7966\n",
      "Epoch 00002: val_accuracy improved from 0.75881 to 0.76542, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.8425 - accuracy: 0.7966 - val_loss: 0.9378 - val_accuracy: 0.7654\n",
      "Epoch 3/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7236 - accuracy: 0.8349\n",
      "Epoch 00003: val_accuracy improved from 0.76542 to 0.82192, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.7235 - accuracy: 0.8349 - val_loss: 0.7587 - val_accuracy: 0.8219\n",
      "Epoch 4/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.8634\n",
      "Epoch 00004: val_accuracy improved from 0.82192 to 0.84014, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.6398 - accuracy: 0.8633 - val_loss: 0.7229 - val_accuracy: 0.8401\n",
      "Epoch 5/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.8851\n",
      "Epoch 00005: val_accuracy did not improve from 0.84014\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.5751 - accuracy: 0.8850 - val_loss: 0.8078 - val_accuracy: 0.8221\n",
      "Epoch 6/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.9037\n",
      "Epoch 00006: val_accuracy improved from 0.84014 to 0.84655, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.5146 - accuracy: 0.9037 - val_loss: 0.7292 - val_accuracy: 0.8466\n",
      "Epoch 7/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4722 - accuracy: 0.9184\n",
      "Epoch 00007: val_accuracy improved from 0.84655 to 0.85757, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4724 - accuracy: 0.9184 - val_loss: 0.6926 - val_accuracy: 0.8576\n",
      "Epoch 8/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4275 - accuracy: 0.9331\n",
      "Epoch 00008: val_accuracy did not improve from 0.85757\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4276 - accuracy: 0.9331 - val_loss: 0.7592 - val_accuracy: 0.8438\n",
      "Epoch 9/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3882 - accuracy: 0.9467\n",
      "Epoch 00009: val_accuracy improved from 0.85757 to 0.86999, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.3881 - accuracy: 0.9467 - val_loss: 0.6690 - val_accuracy: 0.8700\n",
      "Epoch 10/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.9560\n",
      "Epoch 00010: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3566 - accuracy: 0.9560 - val_loss: 0.6953 - val_accuracy: 0.8676\n",
      "Epoch 11/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9638\n",
      "Epoch 00011: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3329 - accuracy: 0.9638 - val_loss: 0.7081 - val_accuracy: 0.8650\n",
      "Epoch 12/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9722\n",
      "Epoch 00012: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3075 - accuracy: 0.9722 - val_loss: 0.7652 - val_accuracy: 0.8682\n",
      "Epoch 13/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9765\n",
      "Epoch 00013: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.2922 - accuracy: 0.9765 - val_loss: 0.7383 - val_accuracy: 0.8684\n",
      "Epoch 14/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2721 - accuracy: 0.9822\n",
      "Epoch 00014: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2720 - accuracy: 0.9823 - val_loss: 0.8399 - val_accuracy: 0.8478\n",
      "Epoch 15/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2610 - accuracy: 0.9855\n",
      "Epoch 00015: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2609 - accuracy: 0.9855 - val_loss: 0.7462 - val_accuracy: 0.8678\n",
      "Epoch 16/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.9910\n",
      "Epoch 00016: val_accuracy did not improve from 0.86999\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2429 - accuracy: 0.9910 - val_loss: 0.7578 - val_accuracy: 0.8696\n",
      "Epoch 17/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2361 - accuracy: 0.9917\n",
      "Epoch 00017: val_accuracy improved from 0.86999 to 0.88001, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2362 - accuracy: 0.9916 - val_loss: 0.7422 - val_accuracy: 0.8800\n",
      "Epoch 18/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9948\n",
      "Epoch 00018: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2268 - accuracy: 0.9948 - val_loss: 0.8798 - val_accuracy: 0.8550\n",
      "Epoch 19/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9937\n",
      "Epoch 00019: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.2260 - accuracy: 0.9937 - val_loss: 0.7581 - val_accuracy: 0.8752\n",
      "Epoch 20/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2154 - accuracy: 0.9966\n",
      "Epoch 00020: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2154 - accuracy: 0.9966 - val_loss: 0.8018 - val_accuracy: 0.8720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.9970\n",
      "Epoch 00021: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2111 - accuracy: 0.9970 - val_loss: 0.7758 - val_accuracy: 0.8770\n",
      "Epoch 22/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9973\n",
      "Epoch 00022: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.2069 - accuracy: 0.9973 - val_loss: 0.8100 - val_accuracy: 0.8702\n",
      "Epoch 23/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9971\n",
      "Epoch 00023: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2054 - accuracy: 0.9971 - val_loss: 0.8001 - val_accuracy: 0.8740\n",
      "Epoch 24/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.9978\n",
      "Epoch 00024: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2004 - accuracy: 0.9978 - val_loss: 0.8265 - val_accuracy: 0.8774\n",
      "Epoch 25/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1969 - accuracy: 0.9981\n",
      "Epoch 00025: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1969 - accuracy: 0.9981 - val_loss: 0.8455 - val_accuracy: 0.8690\n",
      "Epoch 26/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1920 - accuracy: 0.9989\n",
      "Epoch 00026: val_accuracy did not improve from 0.88001\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1920 - accuracy: 0.9989 - val_loss: 0.8118 - val_accuracy: 0.8798\n",
      "Epoch 27/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9993\n",
      "Epoch 00027: val_accuracy improved from 0.88001 to 0.88522, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1884 - accuracy: 0.9993 - val_loss: 0.7877 - val_accuracy: 0.8852\n",
      "Epoch 28/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.9999\n",
      "Epoch 00028: val_accuracy did not improve from 0.88522\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1839 - accuracy: 0.9999 - val_loss: 0.7575 - val_accuracy: 0.8842\n",
      "Epoch 29/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy improved from 0.88522 to 0.88762, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1811 - accuracy: 1.0000 - val_loss: 0.7600 - val_accuracy: 0.8876\n",
      "Epoch 30/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy did not improve from 0.88762\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.8864\n",
      "Epoch 31/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy improved from 0.88762 to 0.88822, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1763 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.8882\n",
      "Epoch 32/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy improved from 0.88822 to 0.88902, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.7487 - val_accuracy: 0.8890\n",
      "Epoch 33/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.88902\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.7463 - val_accuracy: 0.8870\n",
      "Epoch 34/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy improved from 0.88902 to 0.88942, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1696 - accuracy: 1.0000 - val_loss: 0.7504 - val_accuracy: 0.8894\n",
      "Epoch 35/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.7522 - val_accuracy: 0.8888\n",
      "Epoch 36/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1654 - accuracy: 1.0000 - val_loss: 0.7512 - val_accuracy: 0.8880\n",
      "Epoch 37/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.7491 - val_accuracy: 0.8890\n",
      "Epoch 38/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.88942\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.7472 - val_accuracy: 0.8890\n",
      "Epoch 39/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1592 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy improved from 0.88942 to 0.88962, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1592 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.8896\n",
      "Epoch 40/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.88962\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1573 - accuracy: 1.0000 - val_loss: 0.7457 - val_accuracy: 0.8882\n",
      "Epoch 41/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy improved from 0.88962 to 0.89022, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.8902\n",
      "Epoch 42/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1533 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8898\n",
      "Epoch 43/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1514 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.8892\n",
      "Epoch 44/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 0.7434 - val_accuracy: 0.8902\n",
      "Epoch 45/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy improved from 0.89022 to 0.89042, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.7405 - val_accuracy: 0.8904\n",
      "Epoch 46/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.8892\n",
      "Epoch 47/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8888\n",
      "Epoch 48/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1423 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1423 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.8892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.7363 - val_accuracy: 0.8892\n",
      "Epoch 50/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1387 - accuracy: 1.0000 - val_loss: 0.7352 - val_accuracy: 0.8900\n",
      "Epoch 51/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1370 - accuracy: 1.0000 - val_loss: 0.7345 - val_accuracy: 0.8890\n",
      "Epoch 52/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1353 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.7350 - val_accuracy: 0.8892\n",
      "Epoch 53/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 1.0000\n",
      "Epoch 00053: val_accuracy did not improve from 0.89042\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1336 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.8876\n",
      "Epoch 54/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 1.0000\n",
      "Epoch 00054: val_accuracy improved from 0.89042 to 0.89062, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1320 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.8906\n",
      "Epoch 55/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1303 - accuracy: 1.0000\n",
      "Epoch 00055: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 53s 84ms/step - loss: 0.1303 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.8902\n",
      "Epoch 56/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1287 - accuracy: 1.0000\n",
      "Epoch 00056: val_accuracy improved from 0.89062 to 0.89123, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 0.8912\n",
      "Epoch 57/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.7292 - val_accuracy: 0.8896\n",
      "Epoch 58/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "Epoch 00058: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1255 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.8888\n",
      "Epoch 59/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 1.0000\n",
      "Epoch 00059: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8898\n",
      "Epoch 60/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 1.0000\n",
      "Epoch 00060: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.8902\n",
      "Epoch 61/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1209 - accuracy: 1.0000\n",
      "Epoch 00061: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1209 - accuracy: 1.0000 - val_loss: 0.7255 - val_accuracy: 0.8910\n",
      "Epoch 62/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8906\n",
      "Epoch 63/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1179 - accuracy: 1.0000\n",
      "Epoch 00063: val_accuracy did not improve from 0.89123\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1179 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.8906\n",
      "Epoch 64/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 1.0000\n",
      "Epoch 00064: val_accuracy improved from 0.89123 to 0.89183, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8918\n",
      "Epoch 65/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 1.0000\n",
      "Epoch 00065: val_accuracy did not improve from 0.89183\n",
      "625/625 [==============================] - 52s 82ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.8910\n",
      "Epoch 66/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 1.0000\n",
      "Epoch 00066: val_accuracy did not improve from 0.89183\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8916\n",
      "Epoch 67/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 1.0000\n",
      "Epoch 00067: val_accuracy did not improve from 0.89183\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 0.7200 - val_accuracy: 0.8912\n",
      "Epoch 68/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 1.0000\n",
      "Epoch 00068: val_accuracy improved from 0.89183 to 0.89243, saving model to models/vgg16_fold4.h5\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1108 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8924\n",
      "Epoch 69/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 1.0000\n",
      "Epoch 00069: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 52s 84ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8908\n",
      "Epoch 70/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 1.0000\n",
      "Epoch 00070: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.8918\n",
      "Epoch 71/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1067 - accuracy: 1.0000\n",
      "Epoch 00071: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1067 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.8914\n",
      "Epoch 72/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1054 - accuracy: 1.0000\n",
      "Epoch 00072: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.8924\n",
      "Epoch 73/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1041 - accuracy: 1.0000\n",
      "Epoch 00073: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1041 - accuracy: 1.0000 - val_loss: 0.7132 - val_accuracy: 0.8922\n",
      "Epoch 74/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 1.0000\n",
      "Epoch 00074: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.8916\n",
      "Epoch 75/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 1.0000\n",
      "Epoch 00075: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.8920\n",
      "Epoch 76/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1003 - accuracy: 1.0000\n",
      "Epoch 00076: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8922\n",
      "Epoch 77/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/625 [============================>.] - ETA: 0s - loss: 0.0990 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0990 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.8916\n",
      "Epoch 78/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.89243\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.7083 - val_accuracy: 0.8906\n",
      "Epoch 00078: early stopping\n",
      "Epoch 1/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 1.2242 - accuracy: 0.6643\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75761, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 1.2238 - accuracy: 0.6643 - val_loss: 0.9623 - val_accuracy: 0.7576\n",
      "Epoch 2/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.8483 - accuracy: 0.7955\n",
      "Epoch 00002: val_accuracy improved from 0.75761 to 0.82212, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 53s 85ms/step - loss: 0.8484 - accuracy: 0.7954 - val_loss: 0.7868 - val_accuracy: 0.8221\n",
      "Epoch 3/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.7234 - accuracy: 0.8373\n",
      "Epoch 00003: val_accuracy did not improve from 0.82212\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.7235 - accuracy: 0.8372 - val_loss: 0.8309 - val_accuracy: 0.8077\n",
      "Epoch 4/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.6477 - accuracy: 0.8616\n",
      "Epoch 00004: val_accuracy improved from 0.82212 to 0.83934, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.6477 - accuracy: 0.8616 - val_loss: 0.7309 - val_accuracy: 0.8393\n",
      "Epoch 5/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5780 - accuracy: 0.8846\n",
      "Epoch 00005: val_accuracy improved from 0.83934 to 0.85276, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.5778 - accuracy: 0.8846 - val_loss: 0.7026 - val_accuracy: 0.8528\n",
      "Epoch 6/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.9006\n",
      "Epoch 00006: val_accuracy improved from 0.85276 to 0.85717, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.5259 - accuracy: 0.9006 - val_loss: 0.6748 - val_accuracy: 0.8572\n",
      "Epoch 7/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.9189\n",
      "Epoch 00007: val_accuracy did not improve from 0.85717\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.4738 - accuracy: 0.9189 - val_loss: 0.7103 - val_accuracy: 0.8496\n",
      "Epoch 8/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.4320 - accuracy: 0.9303\n",
      "Epoch 00008: val_accuracy improved from 0.85717 to 0.86418, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.4321 - accuracy: 0.9304 - val_loss: 0.6696 - val_accuracy: 0.8642\n",
      "Epoch 9/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3957 - accuracy: 0.9432\n",
      "Epoch 00009: val_accuracy did not improve from 0.86418\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3958 - accuracy: 0.9433 - val_loss: 0.7045 - val_accuracy: 0.8600\n",
      "Epoch 10/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3614 - accuracy: 0.9548\n",
      "Epoch 00010: val_accuracy did not improve from 0.86418\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.3613 - accuracy: 0.9548 - val_loss: 0.6893 - val_accuracy: 0.8642\n",
      "Epoch 11/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.9631\n",
      "Epoch 00011: val_accuracy improved from 0.86418 to 0.87059, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3368 - accuracy: 0.9632 - val_loss: 0.6465 - val_accuracy: 0.8706\n",
      "Epoch 12/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.9727\n",
      "Epoch 00012: val_accuracy improved from 0.87059 to 0.87159, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.3071 - accuracy: 0.9727 - val_loss: 0.6830 - val_accuracy: 0.8716\n",
      "Epoch 13/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.9776\n",
      "Epoch 00013: val_accuracy improved from 0.87159 to 0.87179, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2878 - accuracy: 0.9775 - val_loss: 0.6790 - val_accuracy: 0.8718\n",
      "Epoch 14/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2713 - accuracy: 0.9823\n",
      "Epoch 00014: val_accuracy did not improve from 0.87179\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2712 - accuracy: 0.9823 - val_loss: 0.7705 - val_accuracy: 0.8606\n",
      "Epoch 15/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2576 - accuracy: 0.9863\n",
      "Epoch 00015: val_accuracy did not improve from 0.87179\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2576 - accuracy: 0.9863 - val_loss: 0.7681 - val_accuracy: 0.8608\n",
      "Epoch 16/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2487 - accuracy: 0.9885\n",
      "Epoch 00016: val_accuracy improved from 0.87179 to 0.87360, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2488 - accuracy: 0.9884 - val_loss: 0.7016 - val_accuracy: 0.8736\n",
      "Epoch 17/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2400 - accuracy: 0.9908\n",
      "Epoch 00017: val_accuracy did not improve from 0.87360\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2400 - accuracy: 0.9908 - val_loss: 0.7508 - val_accuracy: 0.8676\n",
      "Epoch 18/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9950\n",
      "Epoch 00018: val_accuracy improved from 0.87360 to 0.87680, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2256 - accuracy: 0.9950 - val_loss: 0.7352 - val_accuracy: 0.8768\n",
      "Epoch 19/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9934\n",
      "Epoch 00019: val_accuracy did not improve from 0.87680\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2267 - accuracy: 0.9934 - val_loss: 0.7437 - val_accuracy: 0.8718\n",
      "Epoch 20/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2166 - accuracy: 0.9960\n",
      "Epoch 00020: val_accuracy improved from 0.87680 to 0.88061, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2166 - accuracy: 0.9960 - val_loss: 0.7058 - val_accuracy: 0.8806\n",
      "Epoch 21/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2097 - accuracy: 0.9977\n",
      "Epoch 00021: val_accuracy improved from 0.88061 to 0.88261, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2097 - accuracy: 0.9977 - val_loss: 0.7296 - val_accuracy: 0.8826\n",
      "Epoch 22/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9973\n",
      "Epoch 00022: val_accuracy did not improve from 0.88261\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2067 - accuracy: 0.9973 - val_loss: 0.7407 - val_accuracy: 0.8796\n",
      "Epoch 23/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.2028 - accuracy: 0.9981\n",
      "Epoch 00023: val_accuracy did not improve from 0.88261\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.2027 - accuracy: 0.9981 - val_loss: 0.7434 - val_accuracy: 0.8796\n",
      "Epoch 24/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1974 - accuracy: 0.9990\n",
      "Epoch 00024: val_accuracy did not improve from 0.88261\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1974 - accuracy: 0.9991 - val_loss: 0.7373 - val_accuracy: 0.8786\n",
      "Epoch 25/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1960 - accuracy: 0.9983\n",
      "Epoch 00025: val_accuracy improved from 0.88261 to 0.88361, saving model to models/vgg16_fold5.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1960 - accuracy: 0.9983 - val_loss: 0.7546 - val_accuracy: 0.8836\n",
      "Epoch 26/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9989\n",
      "Epoch 00026: val_accuracy did not improve from 0.88361\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1918 - accuracy: 0.9990 - val_loss: 0.7304 - val_accuracy: 0.8832\n",
      "Epoch 27/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9998\n",
      "Epoch 00027: val_accuracy improved from 0.88361 to 0.88442, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1864 - accuracy: 0.9998 - val_loss: 0.7522 - val_accuracy: 0.8844\n",
      "Epoch 28/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9998\n",
      "Epoch 00028: val_accuracy improved from 0.88442 to 0.88662, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1841 - accuracy: 0.9998 - val_loss: 0.7272 - val_accuracy: 0.8866\n",
      "Epoch 29/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1810 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.88662\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.8864\n",
      "Epoch 30/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 1.0000\n",
      "Epoch 00030: val_accuracy improved from 0.88662 to 0.88862, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.8886\n",
      "Epoch 31/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9999\n",
      "Epoch 00031: val_accuracy did not improve from 0.88862\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1764 - accuracy: 0.9999 - val_loss: 0.7146 - val_accuracy: 0.8872\n",
      "Epoch 32/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.88862\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.7117 - val_accuracy: 0.8884\n",
      "Epoch 33/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.88862\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1718 - accuracy: 1.0000 - val_loss: 0.7111 - val_accuracy: 0.8884\n",
      "Epoch 34/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1697 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy did not improve from 0.88862\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.8884\n",
      "Epoch 35/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy improved from 0.88862 to 0.89022, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1675 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.8902\n",
      "Epoch 36/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1654 - accuracy: 1.0000 - val_loss: 0.7037 - val_accuracy: 0.8888\n",
      "Epoch 37/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1633 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8884\n",
      "Epoch 38/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1613 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.8892\n",
      "Epoch 39/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 50s 81ms/step - loss: 0.1593 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8890\n",
      "Epoch 40/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.89022\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1573 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.8898\n",
      "Epoch 41/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy improved from 0.89022 to 0.89042, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.8904\n",
      "Epoch 42/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy improved from 0.89042 to 0.89062, saving model to models/vgg16_fold5.h5\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.8906\n",
      "Epoch 43/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1515 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.6980 - val_accuracy: 0.8904\n",
      "Epoch 44/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1496 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8890\n",
      "Epoch 45/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1478 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.6951 - val_accuracy: 0.8896\n",
      "Epoch 46/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1459 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.8904\n",
      "Epoch 47/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1441 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1441 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8900\n",
      "Epoch 48/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1423 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.1423 - accuracy: 1.0000 - val_loss: 0.6891 - val_accuracy: 0.8902\n",
      "Epoch 49/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1405 - accuracy: 1.0000 - val_loss: 0.6893 - val_accuracy: 0.8890\n",
      "Epoch 50/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.8890\n",
      "Epoch 51/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 0.6863 - val_accuracy: 0.8896\n",
      "Epoch 52/250\n",
      "624/625 [============================>.] - ETA: 0s - loss: 0.1354 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.89062\n",
      "625/625 [==============================] - 51s 81ms/step - loss: 0.1354 - accuracy: 1.0000 - val_loss: 0.6851 - val_accuracy: 0.8886\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "from modules import utils, vgg16, fcnn, cifar_vgg\n",
    "    \n",
    "model = vgg16(train=False)\n",
    "model.train_kfold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out early stopper epochs for each run we have history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "22\n",
      "53\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "files = ['models/allFeatures_pca1000.npy', 'models/tfFeatures.npy', 'models/vgg16_second.npy',\n",
    "        'models/resnet2_second.npy', 'models/']\n",
    "\n",
    "for f in files:\n",
    "    history = np.load(f, allow_pickle=True).item()\n",
    "    n = len(history['epoch'])\n",
    "    print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
