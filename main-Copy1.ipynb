{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 7s 0us/step\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Epoch 1/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 1.2015 - accuracy: 0.6714\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72316, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 67s 86ms/step - loss: 1.2014 - accuracy: 0.6714 - val_loss: 1.0575 - val_accuracy: 0.7232\n",
      "Epoch 2/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.8061\n",
      "Epoch 00002: val_accuracy improved from 0.72316 to 0.75341, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.8125 - accuracy: 0.8061 - val_loss: 0.9640 - val_accuracy: 0.7534\n",
      "Epoch 3/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6951 - accuracy: 0.8457\n",
      "Epoch 00003: val_accuracy improved from 0.75341 to 0.80769, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 84ms/step - loss: 0.6950 - accuracy: 0.8457 - val_loss: 0.8141 - val_accuracy: 0.8077\n",
      "Epoch 4/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.6207 - accuracy: 0.8689\n",
      "Epoch 00004: val_accuracy improved from 0.80769 to 0.82051, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.6207 - accuracy: 0.8689 - val_loss: 0.7786 - val_accuracy: 0.8205\n",
      "Epoch 5/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5549 - accuracy: 0.8900\n",
      "Epoch 00005: val_accuracy improved from 0.82051 to 0.85417, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 83ms/step - loss: 0.5551 - accuracy: 0.8899 - val_loss: 0.6818 - val_accuracy: 0.8542\n",
      "Epoch 6/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.5041 - accuracy: 0.9076\n",
      "Epoch 00006: val_accuracy improved from 0.85417 to 0.85637, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.5042 - accuracy: 0.9076 - val_loss: 0.6931 - val_accuracy: 0.8564\n",
      "Epoch 7/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.9210\n",
      "Epoch 00007: val_accuracy did not improve from 0.85637\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.4584 - accuracy: 0.9209 - val_loss: 0.6655 - val_accuracy: 0.8540\n",
      "Epoch 8/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.4170 - accuracy: 0.9352\n",
      "Epoch 00008: val_accuracy improved from 0.85637 to 0.86899, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.4169 - accuracy: 0.9352 - val_loss: 0.6408 - val_accuracy: 0.8690\n",
      "Epoch 9/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.3856 - accuracy: 0.9444\n",
      "Epoch 00009: val_accuracy did not improve from 0.86899\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.3857 - accuracy: 0.9444 - val_loss: 0.7603 - val_accuracy: 0.8393\n",
      "Epoch 10/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.9555\n",
      "Epoch 00010: val_accuracy did not improve from 0.86899\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.3510 - accuracy: 0.9555 - val_loss: 0.7160 - val_accuracy: 0.8574\n",
      "Epoch 11/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.9635\n",
      "Epoch 00011: val_accuracy did not improve from 0.86899\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.3257 - accuracy: 0.9635 - val_loss: 0.7625 - val_accuracy: 0.8470\n",
      "Epoch 12/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.9715\n",
      "Epoch 00012: val_accuracy did not improve from 0.86899\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.3018 - accuracy: 0.9715 - val_loss: 0.7392 - val_accuracy: 0.8602\n",
      "Epoch 13/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.9769\n",
      "Epoch 00013: val_accuracy did not improve from 0.86899\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.2806 - accuracy: 0.9769 - val_loss: 0.7214 - val_accuracy: 0.8638\n",
      "Epoch 14/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2630 - accuracy: 0.9817\n",
      "Epoch 00014: val_accuracy improved from 0.86899 to 0.87200, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.2632 - accuracy: 0.9817 - val_loss: 0.6936 - val_accuracy: 0.8720\n",
      "Epoch 15/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2512 - accuracy: 0.9848\n",
      "Epoch 00015: val_accuracy did not improve from 0.87200\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.2513 - accuracy: 0.9848 - val_loss: 0.7269 - val_accuracy: 0.8676\n",
      "Epoch 16/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9869\n",
      "Epoch 00016: val_accuracy did not improve from 0.87200\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.2415 - accuracy: 0.9869 - val_loss: 0.7453 - val_accuracy: 0.8666\n",
      "Epoch 17/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9907\n",
      "Epoch 00017: val_accuracy improved from 0.87200 to 0.87800, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.2287 - accuracy: 0.9906 - val_loss: 0.7075 - val_accuracy: 0.8780\n",
      "Epoch 18/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.9917\n",
      "Epoch 00018: val_accuracy did not improve from 0.87800\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.2219 - accuracy: 0.9917 - val_loss: 0.7525 - val_accuracy: 0.8700\n",
      "Epoch 19/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9931\n",
      "Epoch 00019: val_accuracy did not improve from 0.87800\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.2159 - accuracy: 0.9931 - val_loss: 0.7375 - val_accuracy: 0.8766\n",
      "Epoch 20/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9956\n",
      "Epoch 00020: val_accuracy did not improve from 0.87800\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.2063 - accuracy: 0.9956 - val_loss: 0.7585 - val_accuracy: 0.8702\n",
      "Epoch 21/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9952\n",
      "Epoch 00021: val_accuracy improved from 0.87800 to 0.88021, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.2024 - accuracy: 0.9953 - val_loss: 0.7417 - val_accuracy: 0.8802\n",
      "Epoch 22/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1942 - accuracy: 0.9970\n",
      "Epoch 00022: val_accuracy improved from 0.88021 to 0.88041, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.1942 - accuracy: 0.9970 - val_loss: 0.7475 - val_accuracy: 0.8804\n",
      "Epoch 23/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9984\n",
      "Epoch 00023: val_accuracy improved from 0.88041 to 0.88401, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1873 - accuracy: 0.9984 - val_loss: 0.7209 - val_accuracy: 0.8840\n",
      "Epoch 24/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9978\n",
      "Epoch 00024: val_accuracy did not improve from 0.88401\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1860 - accuracy: 0.9978 - val_loss: 0.7281 - val_accuracy: 0.8806\n",
      "Epoch 25/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1821 - accuracy: 0.9982\n",
      "Epoch 00025: val_accuracy did not improve from 0.88401\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1821 - accuracy: 0.9982 - val_loss: 0.7325 - val_accuracy: 0.8796\n",
      "Epoch 26/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.9984\n",
      "Epoch 00026: val_accuracy did not improve from 0.88401\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1787 - accuracy: 0.9984 - val_loss: 0.7500 - val_accuracy: 0.8806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9977\n",
      "Epoch 00027: val_accuracy did not improve from 0.88401\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.1782 - accuracy: 0.9977 - val_loss: 0.7709 - val_accuracy: 0.8772\n",
      "Epoch 28/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1707 - accuracy: 0.9993\n",
      "Epoch 00028: val_accuracy improved from 0.88401 to 0.88602, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1707 - accuracy: 0.9993 - val_loss: 0.7133 - val_accuracy: 0.8860\n",
      "Epoch 29/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9998\n",
      "Epoch 00029: val_accuracy improved from 0.88602 to 0.88782, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1662 - accuracy: 0.9998 - val_loss: 0.7039 - val_accuracy: 0.8878\n",
      "Epoch 30/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1637 - accuracy: 0.9998\n",
      "Epoch 00030: val_accuracy improved from 0.88782 to 0.88942, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1637 - accuracy: 0.9998 - val_loss: 0.7001 - val_accuracy: 0.8894\n",
      "Epoch 31/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 1.0000\n",
      "Epoch 00031: val_accuracy improved from 0.88942 to 0.88982, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1603 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8898\n",
      "Epoch 32/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1576 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy improved from 0.88982 to 0.89163, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1576 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.8916\n",
      "Epoch 33/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 1.0000\n",
      "Epoch 00033: val_accuracy did not improve from 0.89163\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1551 - accuracy: 1.0000 - val_loss: 0.6928 - val_accuracy: 0.8914\n",
      "Epoch 34/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1527 - accuracy: 1.0000\n",
      "Epoch 00034: val_accuracy improved from 0.89163 to 0.89183, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1527 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8918\n",
      "Epoch 35/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 1.0000\n",
      "Epoch 00035: val_accuracy improved from 0.89183 to 0.89243, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.1503 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8924\n",
      "Epoch 36/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 00036: val_accuracy improved from 0.89243 to 0.89263, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.8926\n",
      "Epoch 37/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 1.0000\n",
      "Epoch 00037: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.6923 - val_accuracy: 0.8918\n",
      "Epoch 38/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1433 - accuracy: 1.0000 - val_loss: 0.6839 - val_accuracy: 0.8920\n",
      "Epoch 39/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 1.0000\n",
      "Epoch 00039: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1411 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 0.8910\n",
      "Epoch 40/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 64s 81ms/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.6837 - val_accuracy: 0.8924\n",
      "Epoch 41/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8916\n",
      "Epoch 42/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.89263\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1346 - accuracy: 1.0000 - val_loss: 0.6783 - val_accuracy: 0.8912\n",
      "Epoch 43/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1325 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy improved from 0.89263 to 0.89323, saving model to models/vgg16_second.h5\n",
      "781/781 [==============================] - 65s 83ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.8932\n",
      "Epoch 44/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 1.0000\n",
      "Epoch 00044: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 63s 80ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 0.8928\n",
      "Epoch 45/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8906\n",
      "Epoch 46/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 1.0000\n",
      "Epoch 00046: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 62s 80ms/step - loss: 0.1265 - accuracy: 1.0000 - val_loss: 0.6737 - val_accuracy: 0.8912\n",
      "Epoch 47/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1245 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.8928\n",
      "Epoch 48/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 1.0000\n",
      "Epoch 00048: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.6726 - val_accuracy: 0.8922\n",
      "Epoch 49/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.6707 - val_accuracy: 0.8914\n",
      "Epoch 50/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1188 - accuracy: 1.0000\n",
      "Epoch 00050: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.8908\n",
      "Epoch 51/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.6693 - val_accuracy: 0.8914\n",
      "Epoch 52/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1152 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 63s 81ms/step - loss: 0.1152 - accuracy: 1.0000 - val_loss: 0.6661 - val_accuracy: 0.8916\n",
      "Epoch 53/250\n",
      "780/781 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 1.0000\n",
      "Epoch 00053: val_accuracy did not improve from 0.89323\n",
      "781/781 [==============================] - 64s 82ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 0.8914\n",
      "Epoch 00053: early stopping\n",
      "TF VGG16 testing accuracy: 89.27000000000001\n"
     ]
    }
   ],
   "source": [
    "from modules import resnet2, vgg16, cifar_vgg, utils, fcnn\n",
    "from scripts import hog_features, flatten_features, composite_features\n",
    "import numpy as np\n",
    "\n",
    "# main code\n",
    "\n",
    "# 1) TF VGG16\n",
    "model = vgg16(train=True, model_path='models/vgg16_second.h5')\n",
    "pred_y = model.predict()\n",
    "true_y =  model.y_test\n",
    "acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "print('TF VGG16 testing accuracy: {}'.format(acc*100))\n",
    "utils.save_model_features(model, 'data/tf_vgg16_features_second')\n",
    "\n",
    "# # 2) TF resnet2\n",
    "# model = resnet2(train=True, model_path='models/resnet2_second.h5')\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('TF Resnet2 testing accuracy: {}'.format(acc*100))\n",
    "# utils.save_model_features(model, 'data/tf_resnet2_features')\n",
    "\n",
    "# # 3) CIFAR-VGG\n",
    "# model = cifar_vgg(train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('TF Resnet2 testing accuracy: {}'.format(acc*100))\n",
    "# utils.save_model_features(model, 'data/cifar_vgg_features')\n",
    "\n",
    "# # 4) Extract HOG features\n",
    "# hog_features('data/hog_features.npy')\n",
    "\n",
    "# # 5) Extract flatten pixel features\n",
    "# flatten_features('data/flatten_features.npy')\n",
    "\n",
    "# 6) Test out feature description by training a simple FCNN on it\n",
    "# #### TF VGG16 features\n",
    "# model = fcnn('data/tf_vgg16_features.npy', 'models/fcnn_tf_vgg16.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with TF VGG16 testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# #### TF Resnet2 features\n",
    "# model = fcnn('data/tf_resnet2_features.npy', 'models/fcnn_tf_resnet2.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with TF Resnet2 testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# #### CIFAR-VGG features\n",
    "# model = fcnn('data/cifar_vgg_features.npy', 'models/fcnn_cifar_vgg.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with CIFAR-VGG testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# #### HOG features\n",
    "# model = fcnn('data/hog_features.npy', 'models/fcnn_hog.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with HOG testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# #### Flatten pixel features\n",
    "# model = fcnn('data/flatten_features.npy', 'models/fcnn_flatten.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with flatten pixels testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# # 7) Create composite feature sets\n",
    "# #### Combine eall 5 feature sets and use 1000 PCA with zscore True\n",
    "# features_list = ['data/tf_vgg16_features.npy',\n",
    "#                  'data/tf_resnet2_features.npy',\n",
    "#                  'data/cifar_vgg_features.npy',\n",
    "#                  'data/hog_features.npy',\n",
    "#                  'data/flatten_features.npy'\n",
    "# ]\n",
    "# composite_features(features_list, 'data/allFeatures_pca1000_features.npy')\n",
    "\n",
    "# #### Combine only tf resnet2 and tf vgg16\n",
    "# features_list = ['data/tf_vgg16_features.npy',\n",
    "#                  'data/tf_resnet2_features.npy',\n",
    "# ]\n",
    "# composite_features(features_list, 'data/tfFeatures_features.npy', zscore=False, pca=False)\n",
    "\n",
    "# # 8) Run FCNN on the 2 composite features\n",
    "# model = fcnn('data/allFeatures_pca1000_features.npy', 'models/allFeatures_pca1000.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with all features plus pca 10000 testing accuracy: {}'.format(acc*100))\n",
    "\n",
    "# model = fcnn('data/tfFeatures_features.npy', 'models/tfFeatures.h5', train=False)\n",
    "# pred_y = model.predict()\n",
    "# true_y =  model.y_test\n",
    "# acc = utils.calculate_accuracy(pred_y, model.y_test)\n",
    "# print('FCNN with transfer learning features testing accuracy: {}'.format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1024)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "jc = np.load('data/tf_resnet2_features.npy', allow_pickle=True)\n",
    "jc[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
